{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, MaxPooling2D, SeparableConv2D, Dense, Concatenate, BatchNormalization, GlobalAveragePooling2D, Add, AveragePooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path, image_size=(120, 120)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = ['Artificial', 'Natural']\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(dataset_path, class_name)\n",
    "        \n",
    "        for file in os.listdir(class_dir):\n",
    "            if file.endswith('.jpg') or file.endswith('.png') or file.endswith('.jpeg'):\n",
    "                img_path = os.path.join(class_dir, file)\n",
    "                img = load_img(img_path, target_size=image_size)\n",
    "                img_array = img_to_array(img)\n",
    "                img_array /= 255.0\n",
    "                images.append(img_array)\n",
    "                \n",
    "                # Append the label to the labels list as a one-hot encoded array\n",
    "                label = to_categorical(class_names.index(class_name), num_classes=2)\n",
    "                labels.append(np.expand_dims(np.stack([label, 1 - label]), axis=0))  # Stack label and 1-label\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Example usage:\n",
    "dataset_path = 'Dataset_7'\n",
    "images, labels = load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into a training set and a hold-out test set\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of splits for k-fold cross-validation\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_head_model():\n",
    "    input_layer = Input(shape=(120, 120, 3))\n",
    "    # First block\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(input_layer)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x1 = x\n",
    "    x1 = Conv2D(128, (1, 1), strides=(2, 2))(x1)\n",
    "\n",
    "    # Second block\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    x = tf.add(x, x1)\n",
    "\n",
    "    x2 = x\n",
    "    x2 = Conv2D(256, (1, 1), strides=(2, 2))(x2)\n",
    "\n",
    "    # Third block\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    x = tf.add(x, x2)\n",
    "\n",
    "    x3 = x\n",
    "    x3 = Conv2D(728, (1, 1), strides=(2, 2))(x3)\n",
    "\n",
    "    # Fourth block\n",
    "    x = SeparableConv2D(728, (3, 3), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SeparableConv2D(728, (3, 3), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    x = tf.add(x, x3)\n",
    "    \n",
    "    # Middle Flow (repeated block)\n",
    "    for _ in range(2):\n",
    "        block_input = x\n",
    "        x = ReLU()(x)\n",
    "        x = SeparableConv2D(728, (3, 3), padding='same')(x)\n",
    "        x = ReLU()(x)\n",
    "        x = SeparableConv2D(728, (3, 3), padding='same')(x)\n",
    "        x = ReLU()(x)\n",
    "        x = SeparableConv2D(728, (3, 3), padding='same')(x)\n",
    "        # Add the block_input (residual connection), not visible in the diagram\n",
    "        x = tf.add(x, block_input)\n",
    "    \n",
    "    x = ReLU()(x)\n",
    "    head_model = Model(inputs=input_layer, outputs=x)\n",
    "    return head_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_model(head_model, num_submodels):\n",
    "    inputs = Input(shape=(120, 120, 3))\n",
    "    head_outputs = head_model(inputs)\n",
    "\n",
    "    submodel_outputs = []\n",
    "    for i in range(num_submodels):\n",
    "        x = SeparableConv2D(4, (3, 3), strides=(2, 2), padding='same')(head_outputs)\n",
    "        x = ReLU()(x)\n",
    "        x = SeparableConv2D(16, (3, 3), strides=(2, 2), padding='same')(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Dense(1, activation='sigmoid', name=f'output_{i}')(x)  # Sigmoid activation for binary classification\n",
    "        submodel_outputs.append(x)\n",
    "    \n",
    "    if len(submodel_outputs) > 1:\n",
    "        ensemble_outputs = Concatenate()(submodel_outputs)\n",
    "    else:\n",
    "        ensemble_outputs = submodel_outputs[0]\n",
    "\n",
    "    ensemble_model = Model(inputs=inputs, outputs=ensemble_outputs)\n",
    "    return ensemble_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "109/109 [==============================] - 70s 616ms/step - loss: 0.6894 - accuracy: 0.6485 - val_loss: 0.6744 - val_accuracy: 0.6637\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 75s 692ms/step - loss: 0.6676 - accuracy: 0.6526 - val_loss: 0.6484 - val_accuracy: 0.6646\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 79s 727ms/step - loss: 0.6520 - accuracy: 0.6527 - val_loss: 0.6406 - val_accuracy: 0.6650\n",
      "Epoch 4/10\n",
      " 56/109 [==============>...............] - ETA: 38s - loss: 0.6433 - accuracy: 0.6567"
     ]
    }
   ],
   "source": [
    "# Instantiate the head model\n",
    "head_model = create_head_model()\n",
    "\n",
    "# Define the number of submodels in the ensemble\n",
    "num_submodels = 2  # Replace with the number of submodels you have\n",
    "\n",
    "# Instantiate the ensemble model\n",
    "ensemble_model = create_ensemble_model(head_model, num_submodels)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# K-fold Cross Validation model evaluation\n",
    "\n",
    "ensemble_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(train_images):\n",
    "    smaller_train_images, val_images = train_images[train_index], train_images[val_index]\n",
    "    smaller_train_labels, val_labels = train_labels[train_index], train_labels[val_index]\n",
    "\n",
    "    history = ensemble_model.fit(\n",
    "        smaller_train_images, smaller_train_labels,\n",
    "        batch_size=32,\n",
    "        epochs=10,\n",
    "        validation_data=(val_images, val_labels)\n",
    "    )\n",
    "\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
